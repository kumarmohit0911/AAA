{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMbxah78lmeV3WvOCPNOQYT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumarmohit0911/AAA/blob/main/IROC_algo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json, os\n",
        "\n",
        "kaggle_creds = {\n",
        "    \"username\": \"kumarmohit0911\",\n",
        "    \"key\": \"KGAT_70d781b0a7eed54b863a6bcb5ab50e9c\"\n",
        "}\n",
        "\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w\") as f:\n",
        "    json.dump(kaggle_creds, f)\n",
        "\n",
        "os.chmod(\"/root/.kaggle/kaggle.json\", 0o600)\n",
        "\n",
        "print(\"kaggle.json created successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FVfTXtIy4_d",
        "outputId": "70c9ce0d-28f8-462d-b8b3-e9a52027073d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json created successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PqFoj27y6Qd",
        "outputId": "89e7d3ed-f554-4bb2-856a-1267311dd799"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2026.1.4)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "0NAn8zr2f38Z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"stealthtechnologies/rock-classification\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4mbvhiTx73s",
        "outputId": "74f298de-b8fe-4e5d-d1d7-865e9c257367"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'rock-classification' dataset.\n",
            "Path to dataset files: /kaggle/input/rock-classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOrAiBaAzfin",
        "outputId": "a577ea41-6843-45ba-a342-7ed493141973"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Rock Data']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q-0OjtNlFrqL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "DATA_DIR = '/root/.cache/kagglehub/datasets/stealthtechnologies/rock-classification/versions/1'\n",
        "os.listdir(DATA_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5jyY_oVzuHE",
        "outputId": "9e0d583e-0110-4086-f1d5-3725766a830e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Rock Data']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "DATA_DIR = '/root/.cache/kagglehub/datasets/stealthtechnologies/rock-classification/versions/1/Rock Data'\n",
        "os.listdir(DATA_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWTrxXSUz05U",
        "outputId": "27357381-41b7-4124-e580-f382bae62a39"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['README.dataset.txt', 'train', 'test', 'README.roboflow.txt', 'valid']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMIB1FmJFwAp",
        "outputId": "ebf58650-cf33-4644-b3ba-8790153842d2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "train_data_paths  = []\n",
        "train_labels = []\n",
        "train_DATA_DIR = '/root/.cache/kagglehub/datasets/stealthtechnologies/rock-classification/versions/1/Rock Data/train'\n",
        "# train_dir_list = os.listdir(train_DATA_DIR)\n",
        "for rock_type in os.listdir(train_DATA_DIR):\n",
        "  if rock_type == 'Shale-(Mudstone)':\n",
        "    ShaleMudstone= os.path.join(train_DATA_DIR,'Shale-(Mudstone)')\n",
        "    for rock_image in os.listdir(ShaleMudstone):\n",
        "      train_data_paths.append(os.path.join(ShaleMudstone, rock_image))\n",
        "      train_labels.append(0)\n",
        "  elif rock_type =='gypsum':\n",
        "    gypsum = os.path.join(train_DATA_DIR,'gypsum')\n",
        "    for rock_image in os.listdir(gypsum):\n",
        "      train_data_paths.append(os.path.join(gypsum,rock_image))\n",
        "      train_labels.append(1)\n",
        "  elif rock_type =='chert':\n",
        "    chert = os.path.join(train_DATA_DIR,'chert')\n",
        "    for rock_image in os.listdir(chert):\n",
        "      train_data_paths.append(os.path.join(chert, rock_image))\n",
        "      train_labels.append(2)\n",
        "  elif rock_type =='Diatomite':\n",
        "    Diatomite = os.path.join(train_DATA_DIR,'Diatomite')\n",
        "    for rock_image in os.listdir(Diatomite):\n",
        "      train_data_paths.append(os.path.join(Diatomite,rock_image))\n",
        "      train_labels.append(3)\n",
        "  elif rock_type =='olivine-basalt':\n",
        "    OlivineBasalt = os.path.join(train_DATA_DIR,'olivine-basalt')\n",
        "    for rock_image in os.listdir(OlivineBasalt):\n",
        "      train_data_paths.append(os.path.join(OlivineBasalt, rock_image))\n",
        "      train_labels.append(4)\n",
        "  elif rock_type =='Siliceous-sinter':\n",
        "    SiliceousSinter = os.path.join(train_DATA_DIR,'Siliceous-sinter')\n",
        "    for rock_image in os.listdir(SiliceousSinter):\n",
        "      train_data_paths.append(os.path.join(SiliceousSinter,rock_image))\n",
        "      train_labels.append(5)\n",
        "  elif rock_type =='Conglomerate':\n",
        "    Conglomerate = os.path.join(train_DATA_DIR,'Conglomerate')\n",
        "    for rock_image in os.listdir(Conglomerate):\n",
        "      train_data_paths.append(os.path.join(Conglomerate,rock_image))\n",
        "      train_labels.append(6)\n",
        "  elif rock_type =='Clay':\n",
        "    Clay = os.path.join(train_DATA_DIR,'Clay')\n",
        "    for rock_image in os.listdir(Clay):\n",
        "      train_data_paths.append(os.path.join(Clay,rock_image))\n",
        "      train_labels.append(7)\n",
        "  elif rock_type =='Basalt':\n",
        "    Basalt = os.path.join(train_DATA_DIR,'Basalt')\n",
        "    for rock_image in os.listdir(Basalt):\n",
        "      train_data_paths.append(os.path.join(Basalt,rock_image))\n",
        "      train_labels.append(8)"
      ],
      "metadata": {
        "id": "uDW9zza2lqZj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al9q78KELGvt",
        "outputId": "3da0504d-fe04-4ab6-dad0-be297809a97d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "combined = list(zip(train_data_paths,train_labels))\n",
        "\n",
        "random.shuffle(combined)\n",
        "train_data_paths,train_labels = zip(*combined)\n",
        "\n",
        "train_data_paths,train_labels = list(train_data_paths),list(train_labels)\n"
      ],
      "metadata": {
        "id": "LCL0-p_HJZo9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BL3hBGim-mv4",
        "outputId": "335510dd-ffcc-4622-ce41-4a1d454ace46"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3687"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpw9LB2A2c5I",
        "outputId": "bc32c33e-1af7-4f88-e1d0-d00842361bf6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3687"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_data_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHIJFvhd2-Hv",
        "outputId": "f75d3b51-69b7-4326-b3f8-7ce99f1fc0cb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import transforms\n",
        "custom_transform = transforms.Compose([\n",
        "    transforms.Resize((128,128)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(\n",
        "        brightness=0.3,\n",
        "        contrast=0.3,\n",
        "        saturation=0.2\n",
        "    ),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "14CBhg9X3sn6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader,Dataset\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "NGF89Qd97aYO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class CustomDataset(Dataset):\n",
        "#   def __init__(self,image_paths,labels,transforms = custom_transform):\n",
        "#     self.images = []\n",
        "#     self.image_paths = image_paths\n",
        "#     self.labels = labels\n",
        "#     self.transforms = transforms\n",
        "#     for img in self.image_paths:\n",
        "#       self.image = Image.open(img).convert('RGB')\n",
        "#       self.images.append(self.image)\n",
        "\n",
        "#   def __len__(self):\n",
        "#     return len(self.images)\n",
        "\n",
        "#   def __getitem__(self, index):\n",
        "\n",
        "#     return self.transforms(self.images[index]),self.labels[index]\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transforms= custom_transform):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = Image.open(self.image_paths[index]).convert('RGB')\n",
        "        image = self.transforms(image)\n",
        "        label = self.labels[index]\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "RHDlNN_tld3S"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train_data_paths,train_labels)\n",
        "train_loader = DataLoader(train_dataset,batch_size=128,shuffle = True,num_workers=2,pin_memory=True,persistent_workers= True)"
      ],
      "metadata": {
        "id": "y6X4o7DWxYV4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "mobilenet_v2 = models.mobilenet_v2(pretrained = True)\n",
        "#removing the classifier and keeping just the extractor\n",
        "#mobilenet_v2.classifier = nn.Identity()\n",
        "#freezing the feature extractor\n",
        "for param in mobilenet_v2.features.parameters():\n",
        "  param.requires_grad = False\n",
        "for param in mobilenet_v2.features[-2:].parameters():\n",
        "  param.requires_grad = True\n",
        "for param in mobilenet_v2.classifier.parameters():\n",
        "  param.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJV1R9WlK_Oq",
        "outputId": "19dfb10c-5008-4b1c-dab9-0c0673750a2b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_v2.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tmJRdJ6GTv8",
        "outputId": "98241da3-6923-4a5e-90a5-63d3e5f8203a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MobileNetV2(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2dNormActivation(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "    (1): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (2): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (3): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (4): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (9): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (10): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (11): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (12): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (13): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (14): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (15): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (16): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (17): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (18): Conv2dNormActivation(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.2, inplace=False)\n",
              "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "learning_rate = 1e-3\n",
        "epochs = 100\n",
        "Criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, mobilenet_v2.parameters()),\n",
        "                        lr= learning_rate)"
      ],
      "metadata": {
        "id": "J6ynlMo7NF4t"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  loss_test = 0\n",
        "  for image,label in train_loader:\n",
        "    #moving to the gpu\n",
        "    image,label = image.to(device),label.to(device)\n",
        "    # forward pass\n",
        "    outputs = mobilenet_v2(image)\n",
        "    # calculate loss\n",
        "    loss = Criterion (outputs,label)\n",
        "    #back pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    #update grads\n",
        "    optimizer.step()\n",
        "    loss_test += loss.item()\n",
        "  print(f'Epoch {epoch + 1} loss {loss_test/ len(train_loader)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWPE74D8sphy",
        "outputId": "e5ab3eab-81c6-4592-e941-48aa839bbc82"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss 3.136114737083172\n",
            "Epoch 2 loss 1.0100318296202297\n",
            "Epoch 3 loss 0.7831796037739721\n",
            "Epoch 4 loss 0.5944240082954538\n",
            "Epoch 5 loss 0.5192400638399453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.cuda.amp import autocast, GradScaler\n",
        "scaler = GradScaler()\n",
        "for epoch in range(epochs):\n",
        "    mobilenet_v2.train()\n",
        "    loss_test = 0.0\n",
        "\n",
        "    for image, label in train_loader:\n",
        "        image = image.to(device, non_blocking=True)\n",
        "        label = label.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass with AMP\n",
        "        with autocast():\n",
        "            outputs = mobilenet_v2(image)\n",
        "            loss = Criterion(outputs, label)\n",
        "\n",
        "        # backward with scaled gradients\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        loss_test += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} loss {loss_test / len(train_loader)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyjjkfsVG-Jy",
        "outputId": "bc18eabb-66c6-4a37-ce91-4b12fdebb7b0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4012115268.py:2: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/tmp/ipython-input-4012115268.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss 0.30173373736184217\n",
            "Epoch 2 loss 0.2522984085411861\n",
            "Epoch 3 loss 0.20678622378357525\n",
            "Epoch 4 loss 0.18728025899878864\n",
            "Epoch 5 loss 0.15181569934918962\n",
            "Epoch 6 loss 0.17249118665169025\n",
            "Epoch 7 loss 0.18263313611005916\n",
            "Epoch 8 loss 0.14599235150320777\n",
            "Epoch 9 loss 0.14942814769416018\n",
            "Epoch 10 loss 0.13764474682252983\n",
            "Epoch 11 loss 0.11327912568532188\n",
            "Epoch 12 loss 0.11553752242491164\n",
            "Epoch 13 loss 0.11379748030469336\n",
            "Epoch 14 loss 0.1088581095481741\n",
            "Epoch 15 loss 0.1147005326789001\n",
            "Epoch 16 loss 0.10003278545778373\n",
            "Epoch 17 loss 0.08039103833765819\n",
            "Epoch 18 loss 0.07915367571444347\n",
            "Epoch 19 loss 0.09478211312972266\n",
            "Epoch 20 loss 0.0920215396146322\n",
            "Epoch 21 loss 0.10576178351866788\n",
            "Epoch 22 loss 0.09821312861709759\n",
            "Epoch 23 loss 0.08360467183178868\n",
            "Epoch 24 loss 0.07484788614614256\n",
            "Epoch 25 loss 0.08440369765820174\n",
            "Epoch 26 loss 0.08255280348761328\n",
            "Epoch 27 loss 0.0744969489630954\n",
            "Epoch 28 loss 0.06650140361282332\n",
            "Epoch 29 loss 0.09725585689061675\n",
            "Epoch 30 loss 0.08598829638855211\n",
            "Epoch 31 loss 0.08639501048059299\n",
            "Epoch 32 loss 0.06863215591373115\n",
            "Epoch 33 loss 0.06187182501086901\n",
            "Epoch 34 loss 0.06829621816246674\n",
            "Epoch 35 loss 0.0739289123308042\n",
            "Epoch 36 loss 0.06901360277471871\n",
            "Epoch 37 loss 0.06595969212980106\n",
            "Epoch 38 loss 0.0723041975228437\n",
            "Epoch 39 loss 0.06423831069520836\n",
            "Epoch 40 loss 0.047749242616881585\n",
            "Epoch 41 loss 0.05196787754137968\n",
            "Epoch 42 loss 0.0619940002737888\n",
            "Epoch 43 loss 0.05869308117263276\n",
            "Epoch 44 loss 0.0683558977626521\n",
            "Epoch 45 loss 0.06848794941244454\n",
            "Epoch 46 loss 0.06553737160846076\n",
            "Epoch 47 loss 0.06572551951454632\n",
            "Epoch 48 loss 0.05734421120121561\n",
            "Epoch 49 loss 0.06645277010854976\n",
            "Epoch 50 loss 0.049440947361290455\n",
            "Epoch 51 loss 0.04985972904953463\n",
            "Epoch 52 loss 0.039913316674787425\n",
            "Epoch 53 loss 0.0473446284966736\n",
            "Epoch 54 loss 0.043674432833133076\n",
            "Epoch 55 loss 0.04215021145626389\n",
            "Epoch 56 loss 0.055041239500559606\n",
            "Epoch 57 loss 0.03917856549779917\n",
            "Epoch 58 loss 0.04816463205899144\n",
            "Epoch 59 loss 0.04507265930417283\n",
            "Epoch 60 loss 0.06369381979236315\n",
            "Epoch 61 loss 0.049955129719756804\n",
            "Epoch 62 loss 0.04706560829975482\n",
            "Epoch 63 loss 0.0492228695416245\n",
            "Epoch 64 loss 0.05064986993012757\n",
            "Epoch 65 loss 0.04594499649929589\n",
            "Epoch 66 loss 0.0600909177085449\n",
            "Epoch 67 loss 0.05303479792100602\n",
            "Epoch 68 loss 0.05375944867987057\n",
            "Epoch 69 loss 0.040366117296547724\n",
            "Epoch 70 loss 0.04422031095701045\n",
            "Epoch 71 loss 0.038373819295445394\n",
            "Epoch 72 loss 0.039315556432923365\n",
            "Epoch 73 loss 0.04303846472938513\n",
            "Epoch 74 loss 0.0389681166872896\n",
            "Epoch 75 loss 0.0335165859232175\n",
            "Epoch 76 loss 0.051728549798757864\n",
            "Epoch 77 loss 0.05663800461153532\n",
            "Epoch 78 loss 0.03749004105940975\n",
            "Epoch 79 loss 0.04350041999513733\n",
            "Epoch 80 loss 0.04437420019430333\n",
            "Epoch 81 loss 0.059427717058309196\n",
            "Epoch 82 loss 0.06363205778701551\n",
            "Epoch 83 loss 0.03923375692603917\n",
            "Epoch 84 loss 0.04883095394049225\n",
            "Epoch 85 loss 0.042276897820933114\n",
            "Epoch 86 loss 0.04361588128938757\n",
            "Epoch 87 loss 0.04318418434082434\n",
            "Epoch 88 loss 0.04328321527432779\n",
            "Epoch 89 loss 0.03076927607943272\n",
            "Epoch 90 loss 0.04115158945707412\n",
            "Epoch 91 loss 0.045860928097932505\n",
            "Epoch 92 loss 0.03877677643222028\n",
            "Epoch 93 loss 0.06421043235680153\n",
            "Epoch 94 loss 0.05256054566466603\n",
            "Epoch 95 loss 0.04362758358233962\n",
            "Epoch 96 loss 0.04028918003213817\n",
            "Epoch 97 loss 0.05491618927696656\n",
            "Epoch 98 loss 0.04420257908902291\n",
            "Epoch 99 loss 0.04145761871517732\n",
            "Epoch 100 loss 0.04421976337145115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia7uEH3QG_O6",
        "outputId": "d5fcd417-340d-42e7-c59e-49469141b4ed"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jan 15 20:13:19 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P0             28W /   70W |     786MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "test_data_paths  = []\n",
        "test_labels = []\n",
        "test_DATA_DIR = '/root/.cache/kagglehub/datasets/stealthtechnologies/rock-classification/versions/1/Rock Data/test'\n",
        "# train_dir_list = os.listdir(test_DATA_DIR)\n",
        "for rock_type in os.listdir(test_DATA_DIR):\n",
        "  if rock_type == 'Shale-(Mudstone)':\n",
        "    ShaleMudstone= os.path.join(test_DATA_DIR,'Shale-(Mudstone)')\n",
        "    for rock_image in os.listdir(ShaleMudstone):\n",
        "      test_data_paths.append(os.path.join(ShaleMudstone, rock_image))\n",
        "      test_labels.append(0)\n",
        "  elif rock_type =='gypsum':\n",
        "    gypsum = os.path.join(test_DATA_DIR,'gypsum')\n",
        "    for rock_image in os.listdir(gypsum):\n",
        "      test_data_paths.append(os.path.join(gypsum,rock_image))\n",
        "      test_labels.append(1)\n",
        "  elif rock_type =='chert':\n",
        "    chert = os.path.join(test_DATA_DIR,'chert')\n",
        "    for rock_image in os.listdir(chert):\n",
        "      test_data_paths.append(os.path.join(chert, rock_image))\n",
        "      test_labels.append(2)\n",
        "  elif rock_type =='Diatomite':\n",
        "    Diatomite = os.path.join(test_DATA_DIR,'Diatomite')\n",
        "    for rock_image in os.listdir(Diatomite):\n",
        "      test_data_paths.append(os.path.join(Diatomite,rock_image))\n",
        "      test_labels.append(3)\n",
        "  elif rock_type =='olivine-basalt':\n",
        "    OlivineBasalt = os.path.join(test_DATA_DIR,'olivine-basalt')\n",
        "    for rock_image in os.listdir(OlivineBasalt):\n",
        "      test_data_paths.append(os.path.join(OlivineBasalt, rock_image))\n",
        "      test_labels.append(4)\n",
        "  elif rock_type =='Siliceous-sinter':\n",
        "    SiliceousSinter = os.path.join(test_DATA_DIR,'Siliceous-sinter')\n",
        "    for rock_image in os.listdir(SiliceousSinter):\n",
        "      test_data_paths.append(os.path.join(SiliceousSinter,rock_image))\n",
        "      test_labels.append(5)\n",
        "  elif rock_type =='Conglomerate':\n",
        "    Conglomerate = os.path.join(test_DATA_DIR,'Conglomerate')\n",
        "    for rock_image in os.listdir(Conglomerate):\n",
        "      test_data_paths.append(os.path.join(Conglomerate,rock_image))\n",
        "      test_labels.append(6)\n",
        "  elif rock_type =='Clay':\n",
        "    Clay = os.path.join(test_DATA_DIR,'Clay')\n",
        "    for rock_image in os.listdir(Clay):\n",
        "      test_data_paths.append(os.path.join(Clay,rock_image))\n",
        "      test_labels.append(7)\n",
        "  elif rock_type =='Basalt':\n",
        "    Basalt = os.path.join(test_DATA_DIR,'Basalt')\n",
        "    for rock_image in os.listdir(Basalt):\n",
        "      test_data_paths.append(os.path.join(Basalt,rock_image))\n",
        "      test_labels.append(8)"
      ],
      "metadata": {
        "id": "KcXS7RpZHlGr"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQGK5hVoU04Y",
        "outputId": "f8fa0253-8865-4dbf-c430-655eaa5065e5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "174"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = CustomDataset(test_data_paths,test_labels)\n",
        "test_loader = DataLoader(test_dataset,batch_size=128,shuffle = False,num_workers=2,pin_memory=True,persistent_workers= True)"
      ],
      "metadata": {
        "id": "R-meknuGU_GL"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device, topk=(1, 5)):\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    correct_top1 = 0\n",
        "    correct_top5 = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Top-k predictions\n",
        "            _, pred = outputs.topk(max(topk), dim=1, largest=True, sorted=True)\n",
        "            pred = pred.t()  # shape: (k, batch_size)\n",
        "\n",
        "            correct = pred.eq(labels.view(1, -1).expand_as(pred))\n",
        "\n",
        "            correct_top1 += correct[:1].reshape(-1).float().sum(0).item()\n",
        "            correct_top5 += correct[:5].reshape(-1).float().sum(0).item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    top1_acc = 100.0 * correct_top1 / total\n",
        "    top5_acc = 100.0 * correct_top5 / total\n",
        "\n",
        "    return avg_loss, top1_acc, top5_acc\n"
      ],
      "metadata": {
        "id": "UXFOGXo6VcI2"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, top1_acc, top5_acc = evaluate(\n",
        "    mobilenet_v2,\n",
        "    test_loader,\n",
        "    Criterion,\n",
        "    device\n",
        ")\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Top-1 Accuracy: {top1_acc:.2f}%\")\n",
        "print(f\"Top-5 Accuracy: {top5_acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15264dCSWOcY",
        "outputId": "a085920b-bbc2-411c-cf42-31f1cde8b93f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.7785\n",
            "Top-1 Accuracy: 67.82%\n",
            "Top-5 Accuracy: 94.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dQRpNFn8WRdZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
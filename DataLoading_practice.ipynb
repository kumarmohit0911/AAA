{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGpUAvsgYRmLRxK6klROMN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumarmohit0911/AAA/blob/main/DataLoading_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TomqcfSDX329",
        "outputId": "af8804a8-45db-4c3e-e2ff-e6579810170c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json created successfully\n"
          ]
        }
      ],
      "source": [
        "import json, os\n",
        "\n",
        "kaggle_creds = {\n",
        "    \"username\": \"kumarmohit0911\",\n",
        "    \"key\": \"KGAT_70d781b0a7eed54b863a6bcb5ab50e9c\"\n",
        "}\n",
        "\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w\") as f:\n",
        "    json.dump(kaggle_creds, f)\n",
        "\n",
        "os.chmod(\"/root/.kaggle/kaggle.json\", 0o600)\n",
        "\n",
        "print(\"kaggle.json created successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rsvkIccZFkX",
        "outputId": "4cecec1f-4b86-48ec-dd3b-a561225df939"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"kaustubhb999/tomatoleaf\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6sLTnmFZIrM",
        "outputId": "f445514c-e02f-4430-e8d8-f80d828e2366"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'tomatoleaf' dataset.\n",
            "Path to dataset files: /kaggle/input/tomatoleaf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "DATA_DIR = '/root/.cache/kagglehub/datasets/kaustubhb999/tomatoleaf/versions/1/tomato'\n",
        "\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "train_data = os.path.join(DATA_DIR,\"train\")\n",
        "val_data = os.path.join(DATA_DIR,'val')\n",
        "for disease_type in os.listdir(train_data):\n",
        "  disease_path = os.path.join(train_data,disease_type)\n",
        "  if disease_type == 'Tomato___Bacterial_spot':\n",
        "    for img in os.listdir(disease_path):\n",
        "      image_paths.append(os.path.join(disease_path,img))\n",
        "      labels.append(0)\n",
        "  elif disease_type == 'Tomato___Early_blight':\n",
        "    for img in os.listdir(disease_path):\n",
        "      image_paths.append(os.path.join(disease_path,img))\n",
        "      labels.append(1)\n",
        "  elif disease_type == 'Tomato___healthy':\n",
        "    for img in os.listdir(disease_path):\n",
        "      image_paths.append(os.path.join(disease_path,img))\n",
        "      labels.append(2)\n",
        "  elif disease_type == 'Tomato___Late_blight':\n",
        "    for img in os.listdir(disease_path):\n",
        "      image_paths.append(os.path.join(disease_path,img))\n",
        "      labels.append(3)\n",
        "  elif disease_type == 'Tomato___Leaf_Mold':\n",
        "    for img in os.listdir(disease_path):\n",
        "      image_paths.append(os.path.join(disease_path,img))\n",
        "      labels.append(4)\n",
        "  elif disease_type == 'Tomato___Septoria_leaf_spot':\n",
        "    for img in os.listdir(disease_path):\n",
        "      image_paths.append(os.path.join(disease_path,img))\n",
        "      labels.append(5)\n",
        "  elif disease_type == 'Tomato___Spider_mites Two-spotted_spider_mite':\n",
        "    for img in os.listdir(disease_path):\n",
        "      image_paths.append(os.path.join(disease_path,img))\n",
        "      labels.append(6)\n",
        "  elif disease_type == 'Tomato___Target_Spot':\n",
        "    for img in os.listdir(disease_path):\n",
        "      image_paths.append(os.path.join(disease_path,img))\n",
        "      labels.append(7)\n",
        "  elif disease_type == 'Tomato___Tomato_mosaic_virus':\n",
        "    for img in os.listdir(disease_path):\n",
        "      image_paths.append(os.path.join(disease_path,img))\n",
        "      labels.append(8)\n",
        "  elif disease_type == 'Tomato___Tomato_Yellow_Leaf_Curl_Virus':\n",
        "    for img in os.listdir(disease_path):\n",
        "      image_paths.append(os.path.join(disease_path,img))\n",
        "      labels.append(9)"
      ],
      "metadata": {
        "id": "sxfZkufjd7X2"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "DATA_DIR = '/root/.cache/kagglehub/datasets/kaustubhb999/tomatoleaf/versions/1/tomato'\n",
        "\n",
        "image_paths_val = []\n",
        "labels_val = []\n",
        "\n",
        "val_data = os.path.join(DATA_DIR,'val')\n",
        "\n",
        "for disease_type in os.listdir(val_data):\n",
        "  disease_path = os.path.join(val_data,disease_type)\n",
        "  if disease_type == 'Tomato___Bacterial_spot':\n",
        "    for img in os.listdir(disease_path):\n",
        "      image_paths_val.append(os.path.join(disease_path,img))\n",
        "      labels_val.append(0)\n",
        "  elif disease_type == 'Tomato___Early_blight':\n",
        "    for img in os.listdir(disease_path):\n",
        "      image_paths_val.append(os.path.join(disease_path,img))\n",
        "      labels_val.append(1)\n",
        "  elif disease_type == 'Tomato___healthy':\n",
        "    for img in os.listdir(disease_path):\n",
        "      image_paths_val.append(os.path.join(disease_path,img))\n",
        "      labels_val.append(2)\n",
        "  elif disease_type == 'Tomato___Late_blight':\n",
        "    for img in os.listdir(disease_path):\n",
        "      image_paths_val.append(os.path.join(disease_path,img))\n",
        "      labels_val.append(3)\n",
        "  elif disease_type == 'Tomato___Leaf_Mold':\n",
        "    for img in os.listdir(disease_path):\n",
        "      image_paths_val.append(os.path.join(disease_path,img))\n",
        "      labels_val.append(4)\n",
        "  elif disease_type == 'Tomato___Septoria_leaf_spot':\n",
        "    for img in os.listdir(disease_path):\n",
        "      image_paths_val.append(os.path.join(disease_path,img))\n",
        "      labels_val.append(5)\n",
        "  elif disease_type == 'Tomato___Spider_mites Two-spotted_spider_mite':\n",
        "    for img in os.listdir(disease_path):\n",
        "      image_paths_val.append(os.path.join(disease_path,img))\n",
        "      labels_val.append(6)\n",
        "  elif disease_type == 'Tomato___Target_Spot':\n",
        "    for img in os.listdir(disease_path):\n",
        "      image_paths_val.append(os.path.join(disease_path,img))\n",
        "      labels_val.append(7)\n",
        "  elif disease_type == 'Tomato___Tomato_mosaic_virus':\n",
        "    for img in os.listdir(disease_path):\n",
        "      image_paths_val.append(os.path.join(disease_path,img))\n",
        "      labels_val.append(8)\n",
        "  elif disease_type == 'Tomato___Tomato_Yellow_Leaf_Curl_Virus':\n",
        "    for img in os.listdir(disease_path):\n",
        "      image_paths_val.append(os.path.join(disease_path,img))\n",
        "      labels_val.append(9)"
      ],
      "metadata": {
        "id": "tMJpiff-Z-mw"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for train data\n",
        "import random\n",
        "#zip everything\n",
        "combined = list(zip(image_paths,labels))\n",
        "#shuffle\n",
        "random.shuffle(combined)\n",
        "#unzip\n",
        "image_paths,labels = zip(*combined)\n",
        "image_paths,labels = list(image_paths),list(labels)"
      ],
      "metadata": {
        "id": "4bi5rWHlMXZ9"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test data\n",
        "import random\n",
        "#zip everything\n",
        "combined = list(zip(image_paths_val,labels_val))\n",
        "#shuffle\n",
        "random.shuffle(combined)\n",
        "#unzip\n",
        "image_paths_val,labels_val = zip(*combined)\n",
        "image_paths_val,labels_val = list(image_paths_val),list(labels_val)"
      ],
      "metadata": {
        "id": "xceBpMP1cP2_"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "nHGeCcQPpiY2"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "my_transform = transforms.Compose([\n",
        "    transforms.Resize((128,128)),\n",
        "    # transforms.RandomRotation(degrees=45),\n",
        "    # transforms.ColorJitter(brightness=0.5,contrast=0.5),\n",
        "    # transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.ToTensor()\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "uXK7OwWTH4cA"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self,image_paths,labels,transforms=my_transform):\n",
        "    self.image_paths = image_paths\n",
        "    self.labels = labels\n",
        "    self.transforms= transforms\n",
        "  def __len__(self):\n",
        "    return len(self.image_paths)\n",
        "  def __getitem__(self, index):\n",
        "    image = self.image_paths[index]\n",
        "    image = Image.open(image).convert(\"RGB\")\n",
        "    if self.transforms:\n",
        "      image = self.transforms(image)\n",
        "    # get label\n",
        "    label = self.labels[index]\n",
        "    return image , label\n",
        "\n"
      ],
      "metadata": {
        "id": "hwhRpW2xNbyI"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(image_paths, labels)\n",
        "dataset_val = CustomDataset(image_paths_val,labels_val)\n",
        "train_loader = DataLoader(dataset,batch_size=32,num_workers=2,shuffle=True)\n",
        "test_loader = DataLoader(dataset_val,batch_size=32,num_workers=2,shuffle=False)\n",
        "# test_loader = DataLoader(test_dataset,batch_size=32,shuffle=False)"
      ],
      "metadata": {
        "id": "A9Ynth10r0AW"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "img, lbl = dataset_val[0]\n",
        "\n",
        "print(type(img))   # PIL or Tensor\n",
        "print(lbl)         # int (0â€“9)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEgwr_WAD8ZV",
        "outputId": "65ea027e-0c80-46ba-dee2-53897d5486cd"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNN(nn.Module):\n",
        "  def __init__(self,num_feature):\n",
        "    super().__init__()\n",
        "    self.features = nn.Sequential(\n",
        "        nn.Conv2d(num_feature,32,kernel_size=3,padding = \"same\"),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "\n",
        "        nn.Conv2d(32,64,kernel_size=3,padding=\"same\"),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "\n",
        "        nn.Conv2d(64,128,kernel_size=3,padding=\"same\"),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.AdaptiveAvgPool2d((1, 1)),\n",
        "        nn.Flatten(),\n",
        "\n",
        "        nn.Linear(128,32),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.4),\n",
        "        nn.Linear(32,10)\n",
        "\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x= self.features(x)\n",
        "    x= self.classifier(x)\n",
        "    return(x)\n",
        ""
      ],
      "metadata": {
        "id": "AFGCDuSljcdr"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from backcall.backcall import Parameter\n",
        "#setting epochs\n",
        "epochs = 200\n",
        "learning_rate = 1e-3\n",
        "\n",
        "#instatiate model\n",
        "model=MyNN(3)\n",
        "#loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer\n",
        "optimizer = optim.Adam(model.parameters(),lr = learning_rate)"
      ],
      "metadata": {
        "id": "X2BpuRBnsa8D"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  total_loss_per_epoch = 0\n",
        "  for images,label in train_loader:\n",
        "\n",
        "    #forward pass\n",
        "    output = model(images)\n",
        "\n",
        "    #loss calculation\n",
        "    loss = criterion(output,label)\n",
        "\n",
        "\n",
        "    #backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    #update grads\n",
        "    optimizer.step()\n",
        "    total_loss_per_epoch+=loss.item()\n",
        "    avg_loss = total_loss_per_epoch/len(train_loader)\n",
        "  print(f'EPOCH No : {epoch+1} --> Loss : {avg_loss}')\n",
        "  print('_'*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRh1khQWsa4t",
        "outputId": "d365c28f-38b8-41e8-c65c-cba54a700393"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH No : 1 --> Loss : 2.35723876953125\n",
            "__________________________________________________\n",
            "EPOCH No : 2 --> Loss : 2.2142980098724365\n",
            "__________________________________________________\n",
            "EPOCH No : 3 --> Loss : 2.2231693267822266\n",
            "__________________________________________________\n",
            "EPOCH No : 4 --> Loss : 2.053938865661621\n",
            "__________________________________________________\n",
            "EPOCH No : 5 --> Loss : 2.1273257732391357\n",
            "__________________________________________________\n",
            "EPOCH No : 6 --> Loss : 2.050915479660034\n",
            "__________________________________________________\n",
            "EPOCH No : 7 --> Loss : 2.0326085090637207\n",
            "__________________________________________________\n",
            "EPOCH No : 8 --> Loss : 1.9950613975524902\n",
            "__________________________________________________\n",
            "EPOCH No : 9 --> Loss : 1.9758269786834717\n",
            "__________________________________________________\n",
            "EPOCH No : 10 --> Loss : 1.939019799232483\n",
            "__________________________________________________\n",
            "EPOCH No : 11 --> Loss : 1.88309907913208\n",
            "__________________________________________________\n",
            "EPOCH No : 12 --> Loss : 1.9311928749084473\n",
            "__________________________________________________\n",
            "EPOCH No : 13 --> Loss : 1.7687770128250122\n",
            "__________________________________________________\n",
            "EPOCH No : 14 --> Loss : 1.8344614505767822\n",
            "__________________________________________________\n",
            "EPOCH No : 15 --> Loss : 1.803237795829773\n",
            "__________________________________________________\n",
            "EPOCH No : 16 --> Loss : 1.7151097059249878\n",
            "__________________________________________________\n",
            "EPOCH No : 17 --> Loss : 1.755467414855957\n",
            "__________________________________________________\n",
            "EPOCH No : 18 --> Loss : 1.665885090827942\n",
            "__________________________________________________\n",
            "EPOCH No : 19 --> Loss : 1.6721872091293335\n",
            "__________________________________________________\n",
            "EPOCH No : 20 --> Loss : 1.6258233785629272\n",
            "__________________________________________________\n",
            "EPOCH No : 21 --> Loss : 1.6161377429962158\n",
            "__________________________________________________\n",
            "EPOCH No : 22 --> Loss : 1.5742485523223877\n",
            "__________________________________________________\n",
            "EPOCH No : 23 --> Loss : 1.6208789348602295\n",
            "__________________________________________________\n",
            "EPOCH No : 24 --> Loss : 1.6744377613067627\n",
            "__________________________________________________\n",
            "EPOCH No : 25 --> Loss : 1.5465160608291626\n",
            "__________________________________________________\n",
            "EPOCH No : 26 --> Loss : 1.3954013586044312\n",
            "__________________________________________________\n",
            "EPOCH No : 27 --> Loss : 1.4567983150482178\n",
            "__________________________________________________\n",
            "EPOCH No : 28 --> Loss : 1.5615644454956055\n",
            "__________________________________________________\n",
            "EPOCH No : 29 --> Loss : 1.5270593166351318\n",
            "__________________________________________________\n",
            "EPOCH No : 30 --> Loss : 1.4433038234710693\n",
            "__________________________________________________\n",
            "EPOCH No : 31 --> Loss : 1.4092979431152344\n",
            "__________________________________________________\n",
            "EPOCH No : 32 --> Loss : 1.410007119178772\n",
            "__________________________________________________\n",
            "EPOCH No : 33 --> Loss : 1.461010217666626\n",
            "__________________________________________________\n",
            "EPOCH No : 34 --> Loss : 1.3463118076324463\n",
            "__________________________________________________\n",
            "EPOCH No : 35 --> Loss : 1.2755076885223389\n",
            "__________________________________________________\n",
            "EPOCH No : 36 --> Loss : 1.2876498699188232\n",
            "__________________________________________________\n",
            "EPOCH No : 37 --> Loss : 1.2073100805282593\n",
            "__________________________________________________\n",
            "EPOCH No : 38 --> Loss : 1.1602766513824463\n",
            "__________________________________________________\n",
            "EPOCH No : 39 --> Loss : 1.1076339483261108\n",
            "__________________________________________________\n",
            "EPOCH No : 40 --> Loss : 1.2707055807113647\n",
            "__________________________________________________\n",
            "EPOCH No : 41 --> Loss : 1.094330906867981\n",
            "__________________________________________________\n",
            "EPOCH No : 42 --> Loss : 1.022889256477356\n",
            "__________________________________________________\n",
            "EPOCH No : 43 --> Loss : 1.281606912612915\n",
            "__________________________________________________\n",
            "EPOCH No : 44 --> Loss : 1.0521742105484009\n",
            "__________________________________________________\n",
            "EPOCH No : 45 --> Loss : 0.9864253401756287\n",
            "__________________________________________________\n",
            "EPOCH No : 46 --> Loss : 1.207151174545288\n",
            "__________________________________________________\n",
            "EPOCH No : 47 --> Loss : 1.073866367340088\n",
            "__________________________________________________\n",
            "EPOCH No : 48 --> Loss : 0.9087792038917542\n",
            "__________________________________________________\n",
            "EPOCH No : 49 --> Loss : 0.8838146924972534\n",
            "__________________________________________________\n",
            "EPOCH No : 50 --> Loss : 0.9017951488494873\n",
            "__________________________________________________\n",
            "EPOCH No : 51 --> Loss : 0.7168910503387451\n",
            "__________________________________________________\n",
            "EPOCH No : 52 --> Loss : 0.8277031183242798\n",
            "__________________________________________________\n",
            "EPOCH No : 53 --> Loss : 0.7748759984970093\n",
            "__________________________________________________\n",
            "EPOCH No : 54 --> Loss : 0.8201948404312134\n",
            "__________________________________________________\n",
            "EPOCH No : 55 --> Loss : 0.7726252675056458\n",
            "__________________________________________________\n",
            "EPOCH No : 56 --> Loss : 0.6840689182281494\n",
            "__________________________________________________\n",
            "EPOCH No : 57 --> Loss : 0.7476176619529724\n",
            "__________________________________________________\n",
            "EPOCH No : 58 --> Loss : 0.7584076523780823\n",
            "__________________________________________________\n",
            "EPOCH No : 59 --> Loss : 0.811554491519928\n",
            "__________________________________________________\n",
            "EPOCH No : 60 --> Loss : 0.6669206619262695\n",
            "__________________________________________________\n",
            "EPOCH No : 61 --> Loss : 0.5635808706283569\n",
            "__________________________________________________\n",
            "EPOCH No : 62 --> Loss : 0.5853860974311829\n",
            "__________________________________________________\n",
            "EPOCH No : 63 --> Loss : 0.6606752872467041\n",
            "__________________________________________________\n",
            "EPOCH No : 64 --> Loss : 0.4751698672771454\n",
            "__________________________________________________\n",
            "EPOCH No : 65 --> Loss : 0.6838003396987915\n",
            "__________________________________________________\n",
            "EPOCH No : 66 --> Loss : 0.5518311262130737\n",
            "__________________________________________________\n",
            "EPOCH No : 67 --> Loss : 0.581801176071167\n",
            "__________________________________________________\n",
            "EPOCH No : 68 --> Loss : 0.5923447012901306\n",
            "__________________________________________________\n",
            "EPOCH No : 69 --> Loss : 0.5439090132713318\n",
            "__________________________________________________\n",
            "EPOCH No : 70 --> Loss : 0.4501025676727295\n",
            "__________________________________________________\n",
            "EPOCH No : 71 --> Loss : 0.5216789841651917\n",
            "__________________________________________________\n",
            "EPOCH No : 72 --> Loss : 0.4984087646007538\n",
            "__________________________________________________\n",
            "EPOCH No : 73 --> Loss : 0.4598950743675232\n",
            "__________________________________________________\n",
            "EPOCH No : 74 --> Loss : 0.5137711763381958\n",
            "__________________________________________________\n",
            "EPOCH No : 75 --> Loss : 0.4211530387401581\n",
            "__________________________________________________\n",
            "EPOCH No : 76 --> Loss : 0.4191419184207916\n",
            "__________________________________________________\n",
            "EPOCH No : 77 --> Loss : 0.4636915922164917\n",
            "__________________________________________________\n",
            "EPOCH No : 78 --> Loss : 0.3804941177368164\n",
            "__________________________________________________\n",
            "EPOCH No : 79 --> Loss : 0.31947511434555054\n",
            "__________________________________________________\n",
            "EPOCH No : 80 --> Loss : 0.3061724603176117\n",
            "__________________________________________________\n",
            "EPOCH No : 81 --> Loss : 0.2620435953140259\n",
            "__________________________________________________\n",
            "EPOCH No : 82 --> Loss : 0.2756969928741455\n",
            "__________________________________________________\n",
            "EPOCH No : 83 --> Loss : 0.3194851279258728\n",
            "__________________________________________________\n",
            "EPOCH No : 84 --> Loss : 0.24371807277202606\n",
            "__________________________________________________\n",
            "EPOCH No : 85 --> Loss : 0.22060661017894745\n",
            "__________________________________________________\n",
            "EPOCH No : 86 --> Loss : 0.26835012435913086\n",
            "__________________________________________________\n",
            "EPOCH No : 87 --> Loss : 0.2864723801612854\n",
            "__________________________________________________\n",
            "EPOCH No : 88 --> Loss : 0.226395845413208\n",
            "__________________________________________________\n",
            "EPOCH No : 89 --> Loss : 0.2767448127269745\n",
            "__________________________________________________\n",
            "EPOCH No : 90 --> Loss : 0.2539021074771881\n",
            "__________________________________________________\n",
            "EPOCH No : 91 --> Loss : 0.3359154760837555\n",
            "__________________________________________________\n",
            "EPOCH No : 92 --> Loss : 0.256045401096344\n",
            "__________________________________________________\n",
            "EPOCH No : 93 --> Loss : 0.3100939989089966\n",
            "__________________________________________________\n",
            "EPOCH No : 94 --> Loss : 0.18109194934368134\n",
            "__________________________________________________\n",
            "EPOCH No : 95 --> Loss : 0.19392827153205872\n",
            "__________________________________________________\n",
            "EPOCH No : 96 --> Loss : 0.2210785448551178\n",
            "__________________________________________________\n",
            "EPOCH No : 97 --> Loss : 0.12767952680587769\n",
            "__________________________________________________\n",
            "EPOCH No : 98 --> Loss : 0.2022257298231125\n",
            "__________________________________________________\n",
            "EPOCH No : 99 --> Loss : 0.19374042749404907\n",
            "__________________________________________________\n",
            "EPOCH No : 100 --> Loss : 0.16888388991355896\n",
            "__________________________________________________\n",
            "EPOCH No : 101 --> Loss : 0.17548859119415283\n",
            "__________________________________________________\n",
            "EPOCH No : 102 --> Loss : 0.23268868029117584\n",
            "__________________________________________________\n",
            "EPOCH No : 103 --> Loss : 0.21019555628299713\n",
            "__________________________________________________\n",
            "EPOCH No : 104 --> Loss : 0.11596301943063736\n",
            "__________________________________________________\n",
            "EPOCH No : 105 --> Loss : 0.125657856464386\n",
            "__________________________________________________\n",
            "EPOCH No : 106 --> Loss : 0.19348473846912384\n",
            "__________________________________________________\n",
            "EPOCH No : 107 --> Loss : 0.1978304237127304\n",
            "__________________________________________________\n",
            "EPOCH No : 108 --> Loss : 0.11026933789253235\n",
            "__________________________________________________\n",
            "EPOCH No : 109 --> Loss : 0.13127894699573517\n",
            "__________________________________________________\n",
            "EPOCH No : 110 --> Loss : 0.12213937938213348\n",
            "__________________________________________________\n",
            "EPOCH No : 111 --> Loss : 0.08372648805379868\n",
            "__________________________________________________\n",
            "EPOCH No : 112 --> Loss : 0.16905084252357483\n",
            "__________________________________________________\n",
            "EPOCH No : 113 --> Loss : 0.0920434296131134\n",
            "__________________________________________________\n",
            "EPOCH No : 114 --> Loss : 0.19872768223285675\n",
            "__________________________________________________\n",
            "EPOCH No : 115 --> Loss : 0.09793933480978012\n",
            "__________________________________________________\n",
            "EPOCH No : 116 --> Loss : 0.13709333539009094\n",
            "__________________________________________________\n",
            "EPOCH No : 117 --> Loss : 0.15134748816490173\n",
            "__________________________________________________\n",
            "EPOCH No : 118 --> Loss : 0.1863357424736023\n",
            "__________________________________________________\n",
            "EPOCH No : 119 --> Loss : 0.10827746242284775\n",
            "__________________________________________________\n",
            "EPOCH No : 120 --> Loss : 0.0640181228518486\n",
            "__________________________________________________\n",
            "EPOCH No : 121 --> Loss : 0.24115563929080963\n",
            "__________________________________________________\n",
            "EPOCH No : 122 --> Loss : 0.09615868330001831\n",
            "__________________________________________________\n",
            "EPOCH No : 123 --> Loss : 0.10690929740667343\n",
            "__________________________________________________\n",
            "EPOCH No : 124 --> Loss : 0.2454610913991928\n",
            "__________________________________________________\n",
            "EPOCH No : 125 --> Loss : 0.13144727051258087\n",
            "__________________________________________________\n",
            "EPOCH No : 126 --> Loss : 0.16368116438388824\n",
            "__________________________________________________\n",
            "EPOCH No : 127 --> Loss : 0.08916418999433517\n",
            "__________________________________________________\n",
            "EPOCH No : 128 --> Loss : 0.17509755492210388\n",
            "__________________________________________________\n",
            "EPOCH No : 129 --> Loss : 0.10699077695608139\n",
            "__________________________________________________\n",
            "EPOCH No : 130 --> Loss : 0.07975053042173386\n",
            "__________________________________________________\n",
            "EPOCH No : 131 --> Loss : 0.07141672819852829\n",
            "__________________________________________________\n",
            "EPOCH No : 132 --> Loss : 0.10887140035629272\n",
            "__________________________________________________\n",
            "EPOCH No : 133 --> Loss : 0.08225323259830475\n",
            "__________________________________________________\n",
            "EPOCH No : 134 --> Loss : 0.18663837015628815\n",
            "__________________________________________________\n",
            "EPOCH No : 135 --> Loss : 0.13258501887321472\n",
            "__________________________________________________\n",
            "EPOCH No : 136 --> Loss : 0.10968959331512451\n",
            "__________________________________________________\n",
            "EPOCH No : 137 --> Loss : 0.12202461063861847\n",
            "__________________________________________________\n",
            "EPOCH No : 138 --> Loss : 0.08358407020568848\n",
            "__________________________________________________\n",
            "EPOCH No : 139 --> Loss : 0.10033969581127167\n",
            "__________________________________________________\n",
            "EPOCH No : 140 --> Loss : 0.12608274817466736\n",
            "__________________________________________________\n",
            "EPOCH No : 141 --> Loss : 0.11498098820447922\n",
            "__________________________________________________\n",
            "EPOCH No : 142 --> Loss : 0.116704560816288\n",
            "__________________________________________________\n",
            "EPOCH No : 143 --> Loss : 0.07079321891069412\n",
            "__________________________________________________\n",
            "EPOCH No : 144 --> Loss : 0.2087307721376419\n",
            "__________________________________________________\n",
            "EPOCH No : 145 --> Loss : 0.1694549024105072\n",
            "__________________________________________________\n",
            "EPOCH No : 146 --> Loss : 0.1001942977309227\n",
            "__________________________________________________\n",
            "EPOCH No : 147 --> Loss : 0.10523053258657455\n",
            "__________________________________________________\n",
            "EPOCH No : 148 --> Loss : 0.1083311215043068\n",
            "__________________________________________________\n",
            "EPOCH No : 149 --> Loss : 0.05212356150150299\n",
            "__________________________________________________\n",
            "EPOCH No : 150 --> Loss : 0.19790096580982208\n",
            "__________________________________________________\n",
            "EPOCH No : 151 --> Loss : 0.06910352408885956\n",
            "__________________________________________________\n",
            "EPOCH No : 152 --> Loss : 0.09110569953918457\n",
            "__________________________________________________\n",
            "EPOCH No : 153 --> Loss : 0.06698991358280182\n",
            "__________________________________________________\n",
            "EPOCH No : 154 --> Loss : 0.08993497490882874\n",
            "__________________________________________________\n",
            "EPOCH No : 155 --> Loss : 0.15981143712997437\n",
            "__________________________________________________\n",
            "EPOCH No : 156 --> Loss : 0.08167226612567902\n",
            "__________________________________________________\n",
            "EPOCH No : 157 --> Loss : 0.07644955813884735\n",
            "__________________________________________________\n",
            "EPOCH No : 158 --> Loss : 0.0743335410952568\n",
            "__________________________________________________\n",
            "EPOCH No : 159 --> Loss : 0.0765993520617485\n",
            "__________________________________________________\n",
            "EPOCH No : 160 --> Loss : 0.06194574013352394\n",
            "__________________________________________________\n",
            "EPOCH No : 161 --> Loss : 0.07842954993247986\n",
            "__________________________________________________\n",
            "EPOCH No : 162 --> Loss : 0.0861743837594986\n",
            "__________________________________________________\n",
            "EPOCH No : 163 --> Loss : 0.06408417224884033\n",
            "__________________________________________________\n",
            "EPOCH No : 164 --> Loss : 0.0810856968164444\n",
            "__________________________________________________\n",
            "EPOCH No : 165 --> Loss : 0.040772080421447754\n",
            "__________________________________________________\n",
            "EPOCH No : 166 --> Loss : 0.0694042295217514\n",
            "__________________________________________________\n",
            "EPOCH No : 167 --> Loss : 0.04249411076307297\n",
            "__________________________________________________\n",
            "EPOCH No : 168 --> Loss : 0.06787869334220886\n",
            "__________________________________________________\n",
            "EPOCH No : 169 --> Loss : 0.041079532355070114\n",
            "__________________________________________________\n",
            "EPOCH No : 170 --> Loss : 0.104076087474823\n",
            "__________________________________________________\n",
            "EPOCH No : 171 --> Loss : 0.0473090223968029\n",
            "__________________________________________________\n",
            "EPOCH No : 172 --> Loss : 0.040919311344623566\n",
            "__________________________________________________\n",
            "EPOCH No : 173 --> Loss : 0.04309901222586632\n",
            "__________________________________________________\n",
            "EPOCH No : 174 --> Loss : 0.09956866502761841\n",
            "__________________________________________________\n",
            "EPOCH No : 175 --> Loss : 0.0882897675037384\n",
            "__________________________________________________\n",
            "EPOCH No : 176 --> Loss : 0.08540064841508865\n",
            "__________________________________________________\n",
            "EPOCH No : 177 --> Loss : 0.03349186107516289\n",
            "__________________________________________________\n",
            "EPOCH No : 178 --> Loss : 0.041195064783096313\n",
            "__________________________________________________\n",
            "EPOCH No : 179 --> Loss : 0.0306119192391634\n",
            "__________________________________________________\n",
            "EPOCH No : 180 --> Loss : 0.04570305719971657\n",
            "__________________________________________________\n",
            "EPOCH No : 181 --> Loss : 0.062185391783714294\n",
            "__________________________________________________\n",
            "EPOCH No : 182 --> Loss : 0.027413148432970047\n",
            "__________________________________________________\n",
            "EPOCH No : 183 --> Loss : 0.07580605149269104\n",
            "__________________________________________________\n",
            "EPOCH No : 184 --> Loss : 0.019307730719447136\n",
            "__________________________________________________\n",
            "EPOCH No : 185 --> Loss : 0.0413166768848896\n",
            "__________________________________________________\n",
            "EPOCH No : 186 --> Loss : 0.04807954281568527\n",
            "__________________________________________________\n",
            "EPOCH No : 187 --> Loss : 0.030667278915643692\n",
            "__________________________________________________\n",
            "EPOCH No : 188 --> Loss : 0.009978340938687325\n",
            "__________________________________________________\n",
            "EPOCH No : 189 --> Loss : 0.04492684826254845\n",
            "__________________________________________________\n",
            "EPOCH No : 190 --> Loss : 0.04875878244638443\n",
            "__________________________________________________\n",
            "EPOCH No : 191 --> Loss : 0.130893275141716\n",
            "__________________________________________________\n",
            "EPOCH No : 192 --> Loss : 0.09555989503860474\n",
            "__________________________________________________\n",
            "EPOCH No : 193 --> Loss : 0.05517324432730675\n",
            "__________________________________________________\n",
            "EPOCH No : 194 --> Loss : 0.012499549426138401\n",
            "__________________________________________________\n",
            "EPOCH No : 195 --> Loss : 0.014017557725310326\n",
            "__________________________________________________\n",
            "EPOCH No : 196 --> Loss : 0.053410857915878296\n",
            "__________________________________________________\n",
            "EPOCH No : 197 --> Loss : 0.07513729482889175\n",
            "__________________________________________________\n",
            "EPOCH No : 198 --> Loss : 0.04953756183385849\n",
            "__________________________________________________\n",
            "EPOCH No : 199 --> Loss : 0.04293088987469673\n",
            "__________________________________________________\n",
            "EPOCH No : 200 --> Loss : 0.02889111451804638\n",
            "__________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for images,label in test_loader:\n",
        "    output = model(images)\n",
        "    _,predicted = torch.max(output,1)\n",
        "    total += label.shape[0]\n",
        "    correct += (predicted == label).sum().item()\n",
        "print(correct/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45bDJ-X4sa2j",
        "outputId": "35459bbc-66f3-4543-d50f-7bbe84a1220d"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LDLN9xYGsa0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8rtY2KsgsajO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = CustomDataset(image_paths,labels)"
      ],
      "metadata": {
        "id": "m1vmQSVQOVhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "image,label= test_dataset[24]\n",
        "plt.title(f'Label : {label}')\n",
        "plt.imshow(image)\n"
      ],
      "metadata": {
        "id": "mAj1OSLcQQV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(train_loader))\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "image.shape\n"
      ],
      "metadata": {
        "id": "m1A5Fpi4VCAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6W8XfeKe2sWA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}